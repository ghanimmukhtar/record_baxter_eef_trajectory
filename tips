How to use the Baxter
=====================

Setup commands

kinect

####  launch kinect:

roslaunch freenect_launch freenect.launch rgb_frame_id:=camera_rgb_optical_frame depth_frame_id:=camera_depth_optical_frame


((((((
if camera not calibrated:

publish calibration based on QR code as reference point (both the external (camera_link) and arm camera (base_link) must watch the QR codes):

source /home/chavez/catkin_ws/devel/setup.bash

roslaunch baxter_kinect_calibration baxter_bundle_calibrate_xtion.launch

view onlive results: 

rosrun tf tf_echo /base /camera_link

once we have the matrix transformation from tf tf_echo, we copy the translation and rotation part and publish a static transformation:

last calibration, camera_link and base or torso, for camera in front of the table:
1.38 0.04 0.57 -0.305 0.019 0.952 -0.017
- Translation: [1.38, 0.04, 0.57]
- Rotation: in Quaternion [-0.305, 0.019, 0.952, -0.017]
            in RPY (radian) [0.056, 0.618, -3.089]
            in RPY (degree) [3.210, 35.409, -176.970]


camera_rgb_optical_frame
- Translation: [1.379, 0.085, 0.568]
- Rotation: in Quaternion [0.630, 0.628, -0.342, -0.306]
            in RPY (radian) [-2.190, 0.047, 1.592]
            in RPY (degree) [-125.501, 2.668, 91.192]

static transformation:

rosrun tf static_transform_publisher 1.38 0.04 0.57 -0.305 0.019 0.952 -0.017 /world /camera_link 100
rosrun tf static_transform_publisher 1.379 0.085 0.568 -2.190, 0.047, 1.592 /world /camera_rgb_optical_frame 100

Stop previous runs.

Run static transformation:

rosrun tf static_transform_publisher 1.134 0.14 0.46 -0.504 -0.091 0.853 -0.097 /base /camera_link 100

there is an offset in the translation, you can modify (by hand) this values until you get the desired accuracy

now, we need the transformation with the camera_rgb_optical_frame for the internal CPP matrix (both the external and arm camera must watch the QR codes):

rosrun tf tf_echo /base /camera_rgb_optical_frame

rosrun baxter_examples xdisplay_image.py --file=`rospack find a2l_exp_baxter_actions`/dream_logo.png


)))))))))

#### launch affordance example:

First, launch the camera node (se above)

Second, launch the perception node to extract coordinate points of the objects of intereste (in Omar's code is called poi):

rosrun pr2_ransac_supervoxels pr2_ransac_supervoxels_node

Third, launch the experiment manager (kind of menu that choses an object and action to perform on) to control the perception, action execution and effect detection.

roslaunch baxter_experiment_manager experiment_launcher_innorobot.launch


#### Baxter arm modes:

http://sdk.rethinkrobotics.com/wiki/Arm_Control_Modes

The suggested one is the joint control mode.

to see an example see Omar's baxter_basic_action node, scripts: baxter_basic_actions_ik_moveit, joint_position_basic_actions and remember to copy ik_solver.py because this one performs the IK, cartersian to joint space.



/// carlos /camera_link frame
0.225, 0.084, 1.006 -0.008, 0.516, 0.103, 0.850
- Translation: [0.225, 0.084, 1.006]
- Rotation: in Quaternion [-0.008, 0.516, 0.103, 0.850]
            in RPY (radian) [0.198, 1.075, 0.359]
            in RPY (degree) [11.316, 61.579, 20.575]



/// carlos /camera_rgb_optical_frame
0.220 -0.005 0.988 0.733 -0.630 0.111 -0.231
- Translation: [0.220, -0.005, 0.988]
- Rotation: in Quaternion [0.733, -0.630, 0.111, -0.231]
            in RPY (radian) [-2.637, 0.129, -1.388]
            in RPY (degree) [-151.087, 7.405, -79.521]



/// our calibration stuff for camera infront of the table with regard to /camera_link frame
1.148 0.14 0.3 -0.423 -0.051 0.902 -0.067
- Rotation: in Quaternion [-0.423, -0.051, 0.902, -0.067]
            in RPY (radian) [-0.054, 0.879, -3.019]
            in RPY (degree) [-3.094, 50.370, -172.951]


/// our calibration stuff for camera infront of the table with regard to /camera_rgb_optical_frame
1.267, 0.185, 0.299 0.652, 0.638, -0.297, -0.283
- Translation: [1.267, 0.185, 0.299]
- Rotation: in Quaternion [0.652, 0.638, -0.297, -0.283]
            in RPY (radian) [-2.297, 0.026, 1.561]
            in RPY (degree) [-131.589, 1.500, 89.431]

/// our calibration stuff for camera infront of the table with regard to /camera_depth_optical_frame
1.267 0.160 0.299 0.652 0.638 -0.297 -0.283
- Translation: [1.267, 0.160, 0.299]
- Rotation: in Quaternion [0.652, 0.638, -0.297, -0.283]
            in RPY (radian) [-2.297, 0.026, 1.561]
            in RPY (degree) [-131.589, 1.500, 89.431]



/// our calibration stuff for camera behind the robot
-0.55, 0.18, 0.68 -0.206 0.259 0.540 0.774
- Rotation: in Quaternion [-0.206, 0.259, 0.540, 0.774]
            in RPY (radian) [-0.051, 0.672, 1.201]
            in RPY (degree) [-2.905, 38.521, 68.807]

//helpful tip to launch moveit with kinect camera
roslaunch baxter_moveit_config demo_baxter.launch right_electric_gripper:="true" left_electric_gripper:="true" kinect:="true" camera_link_pose:="1.21 0.2 0.33 -0.438 -0.031 0.898 -0.016"

