How to use the Baxter
=====================

Setup commands

kinect

####  launch kinect:

roslaunch freenect_launch freenect.launch rgb_frame_id:=camera_rgb_optical_frame depth_frame_id:=camera_depth_optical_frame


((((((
if camera not calibrated:

publish calibration based on QR code as reference point (both the external (camera_link) and arm camera (base_link) must watch the QR codes):

source /home/chavez/catkin_ws/devel/setup.bash

roslaunch baxter_kinect_calibration baxter_bundle_calibrate_xtion.launch

view onlive results: 

rosrun tf tf_echo /base /camera_link

once we have the matrix transformation from tf tf_echo, we copy the translation and rotation part and publish a static transformation:

e.g.:

- Translation: [0.222, 0.052, 1.010]
- Rotation: in Quaternion [-0.004, 0.406, -0.002, 0.914]
            in RPY (radian) [-0.014, 0.837, -0.011]
            in RPY (degree) [-0.828, 47.965, -0.654]

Stop previous runs.

Run static transformation:

rosrun tf static_transform_publisher 0.222 0.052 0.9 -0.004 0.406 -0.002 0.914 /base /camera_link 100

there is an offset in the translation, you can modify (by hand) this values until you get the desired accuracy

now, we need the transformation with the camera_rgb_optical_frame for the internal CPP matrix (both the external and arm camera must watch the QR codes):

rosrun tf tf_echo /base /camera_rgb_optical_frame


)))))))))

#### launch affordance example:

First, launch the camera node (se above)

Second, launch the perception node to extract coordinate points of the objects of intereste (in Omar's code is called poi):

rosrun pr2_ransac_supervoxels pr2_ransac_supervoxels_node

Third, launch the experiment manager (kind of menu that choses an object and action to perform on) to control the perception, action execution and effect detection.

roslaunch baxter_experiment_manager experiment_launcher_innorobot.launch


#### Baxter arm modes:

http://sdk.rethinkrobotics.com/wiki/Arm_Control_Modes

The suggested one is the joint control mode.

to see an example see Omar's baxter_basic_action node, scripts: baxter_basic_actions_ik_moveit, joint_position_basic_actions and remember to copy ik_solver.py because this one performs the IK, cartersian to joint space.



/// carlos /camera_link frame
1.135 0.11 0.45 -0.508 -0.104 0.851 -0.089
- Rotation: in Quaternion [-0.508, -0.104, 0.851, -0.089]
            in RPY (radian) [-0.183, 1.081, -3.042]
            in RPY (degree) [-10.465, 61.917, -174.301]


/// carlos /camera_rgb_optical_frame
- Translation: [1.123, 0.153, 0.454]
- Rotation: in Quaternion [0.583, 0.776, -0.164, -0.179]
            in RPY (radian) [-2.659, -0.087, 1.832]
            in RPY (degree) [-152.321, -4.962, 104.943]



/// our calibration stuff for camera infront of the table with regard to /camera_link frame
1.148 0.14 0.3 -0.423 -0.051 0.902 -0.067
- Rotation: in Quaternion [-0.423, -0.051, 0.902, -0.067]
            in RPY (radian) [-0.054, 0.879, -3.019]
            in RPY (degree) [-3.094, 50.370, -172.951]


/// our calibration stuff for camera infront of the table with regard to /camera_rgb_optical_frame
1.267, 0.185, 0.299 0.652, 0.638, -0.297, -0.283
- Translation: [1.267, 0.185, 0.299]
- Rotation: in Quaternion [0.652, 0.638, -0.297, -0.283]
            in RPY (radian) [-2.297, 0.026, 1.561]
            in RPY (degree) [-131.589, 1.500, 89.431]

/// our calibration stuff for camera infront of the table with regard to /camera_depth_optical_frame
1.267 0.160 0.299 0.652 0.638 -0.297 -0.283
- Translation: [1.267, 0.160, 0.299]
- Rotation: in Quaternion [0.652, 0.638, -0.297, -0.283]
            in RPY (radian) [-2.297, 0.026, 1.561]
            in RPY (degree) [-131.589, 1.500, 89.431]



/// our calibration stuff for camera behind the robot
-0.55, 0.18, 0.68 -0.206 0.259 0.540 0.774
- Rotation: in Quaternion [-0.206, 0.259, 0.540, 0.774]
            in RPY (radian) [-0.051, 0.672, 1.201]
            in RPY (degree) [-2.905, 38.521, 68.807]

//helpful tip to launch moveit with kinect camera
roslaunch baxter_moveit_config demo_baxter.launch right_electric_gripper:="true" left_electric_gripper:="true" kinect:="true" camera_link_pose:="1.21 0.2 0.33 -0.438 -0.031 0.898 -0.016"

